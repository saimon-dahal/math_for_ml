# Math for Machine Learning — Core vs Deferred

## CORE (Intuition)

### Statistics & Probability
- [x] [Populations & Sampling](stats/sampling.ipynb)
- [x] [Mean, Median, Mode, Variance & Covariance](stats/descriptive_stats.ipynb)
- [x] [Random Variables & Expected Value](stats/random_vars.ipynb)
- [ ] Common Probability Distributions  
  - [ ] Normal  
  - [ ] Bernoulli  
  - [ ] Binomial  
  - [ ] Uniform 
  - [ ] Poisson  
  - [ ] Exponential  
- [ ] Central Limit Theorem
- [ ] Conditional Probability
- [ ] Bayes’ Theorem
- [ ] Maximum Likelihood Estimation (MLE)
- [ ] Linear Regression
- [ ] Logistic Regression
- [ ] Bias-Variance Tradeoff (Conceptual)

---

### Linear Algebra
- [ ] Scalars, Vectors, Matrices & Tensors
- [ ] Matrix Operations
- [ ] Matrix Rank & Linear Independence
- [ ] Functions & Norms
- [ ] Eigenvalues & Eigenvectors
- [ ] Matrix Decompositions (SVD)
- [ ] Principal Component Analysis (PCA)

---

### Calculus & Optimization
- [ ] Derivatives & Gradients
- [ ] Gradient Descent Algorithm
- [ ] Jacobian & Hessian
- [ ] Chain Rule
- [ ] Regularization (Conceptual)
- [ ] Optimization Fundamentals  
  - [ ] Local vs Global Minima  
  - [ ] Saddle Points  
  - [ ] Convexity  

---
## Deferred (More theoritical)
---

### Probability & Information Theory
- [ ] Entropy
- [ ] Cross-Entropy Loss
- [ ] KL Divergence
- [ ] Bias–Variance Tradeoff (deep dive)
- [ ] Confidence Intervals

---

### Linear Models & Numerical Stability
- [ ] Regularization (L1, L2, Elastic Net) (deep dive)
- [ ] Conditioning of Matrices
- [ ] Numerical Stability
- [ ] Why SVD Beats Normal Equations

---

### Multivariate Statistics
- [ ] Multivariate Gaussian
- [ ] Covariance as Geometry
- [ ] Correlation Structure
- [ ] Whitening

---

### Convex Optimization
- [ ] Convex Sets & Convex Functions
- [ ] KKT Conditions
- [ ] Duality

---