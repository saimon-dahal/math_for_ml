{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adfbcb0f",
   "metadata": {},
   "source": [
    "## Mean\n",
    "\n",
    "The value that minimizes squared error.\n",
    "\n",
    "- linear regression predicts the mean\n",
    "- MSE loss leads to mean estimates\n",
    "- Gaussian likelihoods produce mean estimates\n",
    "\n",
    "Mean = optimal under squared loss\n",
    "\n",
    "## Median\n",
    "\n",
    "The value that minimizes absolute error.\n",
    "\n",
    "- robust to outliers\n",
    "- L1 loss -> median\n",
    "\n",
    "## Mode\n",
    "\n",
    "Most frequent value.\n",
    "The peak of the distribution\n",
    "\n",
    "In continuous distributions, this generalizes to:\n",
    "- Density peaks\n",
    "- MAP estimation (Maximum A Posteriori)\n",
    "\n",
    "In Classification -> Most probable class\n",
    "In Bayesian Inference -> MAP estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce788dc0",
   "metadata": {},
   "source": [
    "How does Mean minimizes the squared error?\n",
    "\n",
    "Squared error is this:\n",
    "- Being far is punished a lot\n",
    "- Being slightly off is punished a little\n",
    "\n",
    "So the best guess:\n",
    "- pulls equally from both sides\n",
    "- Balances large mistakes\n",
    "\n",
    "The only place that balances squared pulling is the **average**\n",
    "\n",
    "\n",
    "How does Median minimize the absolute error?\n",
    "- Absolute error doesn't care how far\n",
    "- Each point pulls with equal strength\n",
    "- the middle wins\n",
    "\n",
    "Median = best guess when all mistakes count equally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801f78fb",
   "metadata": {},
   "source": [
    "## Expected Value\n",
    "\n",
    "Example: Dice\n",
    "\n",
    "You roll a die:\n",
    "\n",
    "- You don’t know what you’ll get\n",
    "- You do know the rules\n",
    "\n",
    "Each roll is random.\n",
    "\n",
    "If you roll:\n",
    "\n",
    "-10 times → average jumps around\n",
    "- 1,000 times → average stabilizes\n",
    "- 1,000,000 times → barely moves\n",
    "\n",
    "That final stable number is 3.5\n",
    "\n",
    "That number is the expected value.\n",
    "\n",
    "So:\n",
    "Expected value = long-run average outcome of a random process\n",
    "\n",
    "\n",
    "In Machine Learning:\n",
    "\n",
    "\"If I had to pick one value that will be least wrong on average, what should I pick?\" Thats the expected value.\n",
    "\n",
    "It is not:\n",
    "- value you will most likely see\n",
    "- not the middle\n",
    "- not the correct answer for one case\n",
    "\n",
    "It is:\n",
    "\"Across all future cases, what single number gives me the smallest average error?\"\n",
    "\n",
    "**Example**\n",
    "\n",
    "Suppose tomorrow’s temperature is uncertain.\n",
    "\n",
    "You must announce one number today.\n",
    "\n",
    "If you repeat this situation many times:\n",
    "\n",
    "Some days you’re too high\n",
    "\n",
    "Some days too low\n",
    "\n",
    "If you average your mistakes across all days, one choice gives the smallest average mistake.\n",
    "\n",
    "That choice corresponds to the expected value of the temperature distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98907f5",
   "metadata": {},
   "source": [
    "## Standard deviation\n",
    "\n",
    "\"How far away from the average (mean) is a typical value?\"\n",
    "\n",
    "Small std dev:\n",
    "- Data tightly clustered\n",
    "- Predictions are reliable\n",
    "\n",
    "Large std dev:\n",
    "- Data scattered\n",
    "- Predictions are risky"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aca19d",
   "metadata": {},
   "source": [
    "## Variance\n",
    "\n",
    "Variance measures spread due to randomness, not error, not bias.\n",
    "\n",
    "Variance tells:\n",
    "- how many samples you need\n",
    "- how reliable your estimates are\n",
    "- how noisy the target is\n",
    "\n",
    "Higher variance -> Harder learning\n",
    "\n",
    "This is why:\n",
    "- More data helps\n",
    "- Averaging helps\n",
    "- Regularization helps\n",
    "\n",
    "All of these reduce effective variance\n",
    "\n",
    "## Covariance\n",
    "\n",
    "Variance looks at one variable\n",
    "Corvariance looks at two variables together.\n",
    "\n",
    "\"when X moves, does Y tend to move with it?\"\n",
    "\n",
    "**Important clarification**\n",
    "\n",
    "Covariance is not:\n",
    "\n",
    "- Strength of relationship (scale matters)\n",
    "- Causation\n",
    "\n",
    "It is:\n",
    "- Direction of shared variation\n",
    "\n",
    "Covariance captures structure."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
